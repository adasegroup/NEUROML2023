{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install monai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9gT_j6zFirQ",
        "outputId": "c44144c9-f0ab-4d29-aba8-3030f15352e8"
      },
      "id": "a9gT_j6zFirQ",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting monai\n",
            "  Downloading monai-1.0.0-202209161346-py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from monai) (1.12.1+cu113)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from monai) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7->monai) (4.1.1)\n",
            "Installing collected packages: monai\n",
            "Successfully installed monai-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bcf49af4-7622-4c67-afdd-f0146e682a8e",
      "metadata": {
        "id": "bcf49af4-7622-4c67-afdd-f0146e682a8e"
      },
      "outputs": [],
      "source": [
        "# Copyright 2020 MONAI Consortium\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import monai\n",
        "from monai.apps import download_and_extract\n",
        "from monai.config import print_config\n",
        "from monai.data import DataLoader, ImageDataset\n",
        "from monai.transforms import (\n",
        "    EnsureChannelFirst,\n",
        "    Compose,\n",
        "    RandRotate90,\n",
        "    Resize,\n",
        "    ScaleIntensity,\n",
        "    CropForeground,\n",
        "    NormalizeIntensity\n",
        ")\n",
        "from monai.data import NibabelReader\n",
        "from monai.networks.blocks import ResidualUnit,Convolution\n",
        "from torch import nn\n",
        "import warnings\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "warnings.warn = warn\n",
        "from IPython import display\n",
        "import random\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Seminar 6.2 : Deep Learning methods for fMRI data"
      ],
      "metadata": {
        "id": "QKCUbCVYhVLw"
      },
      "id": "QKCUbCVYhVLw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the seminar we try to implement 3D CNN+GRU model on ICA fMRI data to classify Schizophrenia vs Control on SchizConnect dataset.\n",
        "\n",
        "fMRI data is 4D tensor with 3 spatial dimensions and one temporal. In last part of seminar we selected 30 ICA components from fMRI data.\n",
        "\n",
        "Data from SchizConnect was preproccesed by fmriprep\n",
        "\n",
        "Useful links:\n",
        "\n",
        "\n",
        "*   Monai docs: https://docs.monai.io/en/latest/api.html\n",
        "*   SchizConnect: http://schizconnect.org/\n",
        "*   fMRIPrep : https://fmriprep.org/en/stable/index.html\n",
        "\n"
      ],
      "metadata": {
        "id": "animW7iyhegM"
      },
      "id": "animW7iyhegM"
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "from pathlib import Path\n",
        "if IN_COLAB:\n",
        "    google.colab.drive.mount(\"/content/drive\")\n",
        "    \n",
        "    # Change this if you created the shortcut in a different location\n",
        "    AUX_DATA_ROOT = Path(\"/content/drive/My Drive/NEUROML\")\n",
        "    \n",
        "    assert AUX_DATA_ROOT.is_dir(), \"Have you forgot to 'Add a shortcut to Drive'?\"\n",
        "    \n",
        "    import sys\n",
        "    sys.path.append(str(AUX_DATA_ROOT))\n",
        "else:\n",
        "    AUX_DATA_ROOT = Path(\".\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xGjijROFZFf",
        "outputId": "bfc4b59f-fb41-40d8-ecdd-34c4b44731ed"
      },
      "id": "-xGjijROFZFf",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "263d57b9-a5bc-443d-a1fe-78c5904b1709",
      "metadata": {
        "id": "263d57b9-a5bc-443d-a1fe-78c5904b1709"
      },
      "outputs": [],
      "source": [
        "pin_memory = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d400a6b4-88e8-4fd0-90de-5774ef7e3fa4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d400a6b4-88e8-4fd0-90de-5774ef7e3fa4",
        "outputId": "b24ed6d4-9727-4648-96f9-e3d77ee5c959"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly, we need to download preprecessed fMRI data:"
      ],
      "metadata": {
        "id": "Glo3iNGIoeoQ"
      },
      "id": "Glo3iNGIoeoQ"
    },
    {
      "cell_type": "code",
      "source": [
        "! wget \"https://s101sas.storage.yandex.net/rdisk/0a856c33bf6fbd84429689663c315247cdb7fe50f0e33984767fadb6c4132045/633618bb/dZndx-jD4XV2UOupXkjAg5iEFaT4yhAfGRDTw4nBc7wG_TERhrAeNyAX_Cq10tnhbjl0twmYuYzASZfIxuYpJA==?uid=0&filename=cobre.zip&disposition=attachment&hash=jCWWei%2Bfei3Sq7nhcjBXsnAClEAC48p18YrBNaN7Q8E8PWGk2CQjN/oYsPfn5Nnvq/J6bpmRyOJonT3VoXnDag%3D%3D&limit=0&content_type=application%2Fzip&owner_uid=222635455&fsize=17790506046&hid=f8c4b0ea13a37fe1fe3a49c8353e87f3&media_type=compressed&tknv=v2&rtoken=B1DCafoW5pIV&force_default=no&ycrid=na-6b7e9eb9609fc48ad454128615b31bb2-downloader9h&ts=5e9d832db64c0&s=e5cbc8f7eda8e40ef04579a42863d5a1fb88658279a8d34263c72565c5f58edf&pb=U2FsdGVkX19AUKt6DwGHOQSACl2ZPIWjE3GZFW5KV4xPAfNDIWeUAoF2Oux53qOVYVT4QVnTD2L7taQ65FAUbOT4ALNN3CyDkMEMDq8UdRo\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivTZnzeYJCMu",
        "outputId": "c041db8c-bec4-424c-9cf6-a68dccc1f5b9"
      },
      "id": "ivTZnzeYJCMu",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The name is too long, 665 chars total.\n",
            "Trying to shorten...\n",
            "New name is dZndx-jD4XV2UOupXkjAg5iEFaT4yhAfGRDTw4nBc7wG_TERhrAeNyAX_Cq10tnhbjl0twmYuYzASZfIxuYpJA==?uid=0&filename=cobre.zip&disposition=attachment&hash=jCWWei+fei3Sq7nhcjBXsnAClEAC48p18YrBNaN7Q8E8PWGk2CQjN%2FoYsPfn5Nnvq%2FJ6bpmRyOJonT3VoXnDag==&l.\n",
            "--2022-09-29 18:57:13--  https://s101sas.storage.yandex.net/rdisk/0a856c33bf6fbd84429689663c315247cdb7fe50f0e33984767fadb6c4132045/633618bb/dZndx-jD4XV2UOupXkjAg5iEFaT4yhAfGRDTw4nBc7wG_TERhrAeNyAX_Cq10tnhbjl0twmYuYzASZfIxuYpJA==?uid=0&filename=cobre.zip&disposition=attachment&hash=jCWWei%2Bfei3Sq7nhcjBXsnAClEAC48p18YrBNaN7Q8E8PWGk2CQjN/oYsPfn5Nnvq/J6bpmRyOJonT3VoXnDag%3D%3D&limit=0&content_type=application%2Fzip&owner_uid=222635455&fsize=17790506046&hid=f8c4b0ea13a37fe1fe3a49c8353e87f3&media_type=compressed&tknv=v2&rtoken=B1DCafoW5pIV&force_default=no&ycrid=na-6b7e9eb9609fc48ad454128615b31bb2-downloader9h&ts=5e9d832db64c0&s=e5cbc8f7eda8e40ef04579a42863d5a1fb88658279a8d34263c72565c5f58edf&pb=U2FsdGVkX19AUKt6DwGHOQSACl2ZPIWjE3GZFW5KV4xPAfNDIWeUAoF2Oux53qOVYVT4QVnTD2L7taQ65FAUbOT4ALNN3CyDkMEMDq8UdRo\n",
            "Resolving s101sas.storage.yandex.net (s101sas.storage.yandex.net)... 37.9.125.101, 2a02:6b8:c02:ca1:0:41af:37b5:1337\n",
            "Connecting to s101sas.storage.yandex.net (s101sas.storage.yandex.net)|37.9.125.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17790506046 (17G) [application/zip]\n",
            "Saving to: ‘dZndx-jD4XV2UOupXkjAg5iEFaT4yhAfGRDTw4nBc7wG_TERhrAeNyAX_Cq10tnhbjl0twmYuYzASZfIxuYpJA==?uid=0&filename=cobre.zip&disposition=attachment&hash=jCWWei+fei3Sq7nhcjBXsnAClEAC48p18YrBNaN7Q8E8PWGk2CQjN%2FoYsPfn5Nnvq%2FJ6bpmRyOJonT3VoXnDag==&l’\n",
            "\n",
            "dZndx-jD4XV2UOupXkj 100%[===================>]  16.57G  19.5MB/s    in 14m 9s  \n",
            "\n",
            "2022-09-29 19:11:23 (20.0 MB/s) - ‘dZndx-jD4XV2UOupXkjAg5iEFaT4yhAfGRDTw4nBc7wG_TERhrAeNyAX_Cq10tnhbjl0twmYuYzASZfIxuYpJA==?uid=0&filename=cobre.zip&disposition=attachment&hash=jCWWei+fei3Sq7nhcjBXsnAClEAC48p18YrBNaN7Q8E8PWGk2CQjN%2FoYsPfn5Nnvq%2FJ6bpmRyOJonT3VoXnDag==&l’ saved [17790506046/17790506046]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.rename('dZndx-jD4XV2UOupXkjAg5iEFaT4yhAfGRDTw4nBc7wG_TERhrAeNyAX_Cq10tnhbjl0twmYuYzASZfIxuYpJA==?uid=0&filename=cobre.zip&disposition=attachment&hash=jCWWei+fei3Sq7nhcjBXsnAClEAC48p18YrBNaN7Q8E8PWGk2CQjN%2FoYsPfn5Nnvq%2FJ6bpmRyOJonT3VoXnDag==&l', 'COBRE_ICA_cleaned.zip')"
      ],
      "metadata": {
        "id": "sg4Rj43UQYgC"
      },
      "id": "sg4Rj43UQYgC",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path ='COBRE_ICA_cleaned/'\n",
        "os.mkdir(data_path)"
      ],
      "metadata": {
        "id": "6XR14Ys9mOlM"
      },
      "id": "6XR14Ys9mOlM",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "count_files =130\n",
        "with zipfile.ZipFile(f\"COBRE_ICA_cleaned.zip\", \"a\") as z:\n",
        "   for file in z.namelist():\n",
        "      if 'fmri.nii' in file:\n",
        "        count_files-=1\n",
        "      if count_files>0:  \n",
        "        z.extract(file, \"COBRE_ICA_cleaned\")"
      ],
      "metadata": {
        "id": "aHbwAJwogJsA"
      },
      "id": "aHbwAJwogJsA",
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "# shutil.copytree(\"COBRE_ICA_cleaned\", AUX_DATA_ROOT /'data/COBRE_ICA_cleaned2')"
      ],
      "metadata": {
        "id": "bdmEhIqOhJof"
      },
      "id": "bdmEhIqOhJof",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Load Nifty fMRI data with MONAI Datasets"
      ],
      "metadata": {
        "id": "fmGTMeEJpP_7"
      },
      "id": "fmGTMeEJpP_7"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "815e535d-16cf-4601-8ace-7ef33efd13b2",
      "metadata": {
        "id": "815e535d-16cf-4601-8ace-7ef33efd13b2"
      },
      "outputs": [],
      "source": [
        "data_path ='COBRE_ICA_cleaned/COBRE_ICA_cleaned'\n",
        "label_path =AUX_DATA_ROOT / \"data/meta_data.tsv\"\n",
        "data_fmriprep_path =Path(data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0ab59d4e-f106-4be2-a6e8-22fe17b839bd",
      "metadata": {
        "id": "0ab59d4e-f106-4be2-a6e8-22fe17b839bd"
      },
      "outputs": [],
      "source": [
        "labels_data =pd.read_csv(label_path, delimiter=\"\\t\")\n",
        "labels_data=labels_data.loc[labels_data['Dx'].isin(['No_Known_Disorder', 'Schizophrenia_Strict'])]\n",
        "labels_data=labels_data[['Subjectid','Dx']].drop_duplicates()\n",
        "labels_data['Dx']=labels_data['Dx'].map({'No_Known_Disorder': 0, 'Schizophrenia_Strict' :1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "23b74723-eff5-4f08-8e5e-defe33e4d732",
      "metadata": {
        "tags": [],
        "id": "23b74723-eff5-4f08-8e5e-defe33e4d732"
      },
      "outputs": [],
      "source": [
        "images =[]\n",
        "labels =[]\n",
        "for raw in labels_data.iterrows():\n",
        "        subj_id=raw[1]['Subjectid']\n",
        "        label=raw[1]['Dx']\n",
        "        brain_path =Path(f'{data_path}/sub-{subj_id}/fmri.nii')\n",
        "        if brain_path.exists():\n",
        "            images.append(brain_path)\n",
        "            labels.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-WforuYWM2o",
        "outputId": "17fa706d-7b57-42fc-86b3-8b080c3de919"
      },
      "id": "j-WforuYWM2o",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "118"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TW5UwuIJzb_A",
        "outputId": "26c02ebe-9ef9-4e16-da29-3d5678aa5110"
      },
      "id": "TW5UwuIJzb_A",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4745762711864407"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a1d00dad-c0a2-437d-a833-29e86f161ffe",
      "metadata": {
        "id": "a1d00dad-c0a2-437d-a833-29e86f161ffe"
      },
      "outputs": [],
      "source": [
        "labels = torch.nn.functional.one_hot(torch.as_tensor(labels)).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "47a20f0f-54b9-4544-a026-e6cb0c075646",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47a20f0f-54b9-4544-a026-e6cb0c075646",
        "outputId": "88569535-96f4-453e-fb4a-c171a44d5289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'monai.data.meta_tensor.MetaTensor'> (2, 30, 32, 32, 32) tensor([[0., 1.],\n",
            "        [0., 1.]]) torch.Size([2, 2])\n"
          ]
        }
      ],
      "source": [
        "# Define transforms\n",
        "train_transforms = Compose([EnsureChannelFirst(),CropForeground(select_fn=lambda x: x > 0, margin=0),NormalizeIntensity(), Resize((32, 32, 32))])\n",
        "\n",
        "val_transforms = Compose([EnsureChannelFirst(),CropForeground(select_fn=lambda x: x > 0, margin=0),NormalizeIntensity(), Resize((32, 32, 32))])\n",
        "\n",
        "# Define nifti dataset, data loader\n",
        "check_ds = ImageDataset(image_files=images, labels=labels, transform=train_transforms)\n",
        "check_loader = DataLoader(check_ds, batch_size=2, num_workers=2, pin_memory=pin_memory)\n",
        "\n",
        "im, label = monai.utils.misc.first(check_loader)\n",
        "print(type(im), im.shape, label, label.shape)\n",
        "\n",
        "# create a training data loader\n",
        "train_ds = ImageDataset(image_files=images[:-30], labels=labels[:-30], transform=train_transforms)\n",
        "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True,pin_memory=pin_memory)\n",
        "\n",
        "# create a validation data loader\n",
        "val_ds = ImageDataset(image_files=images[-30:], labels=labels[-30:], transform=val_transforms)\n",
        "val_loader = DataLoader(val_ds, batch_size=16, pin_memory=pin_memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b00d98d5-d4ff-4a1e-97e0-4a78a1844f63",
      "metadata": {
        "id": "b00d98d5-d4ff-4a1e-97e0-4a78a1844f63"
      },
      "outputs": [],
      "source": [
        "example =next(iter(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b605c2a4-94f5-4f19-b2c2-eb44303dacb4",
      "metadata": {
        "id": "b605c2a4-94f5-4f19-b2c2-eb44303dacb4"
      },
      "outputs": [],
      "source": [
        "def show_slices(image, axis1=\"x\", axis2=\"y\", axis3=\"z\"):\n",
        "    slice_0 = image[round(len(image[0])/2), :, :]\n",
        "    slice_1 = image[:, round(len(image[1])/2), :]\n",
        "    slice_2 = image[:, :, round(len(image[2])/2)]\n",
        "    image = ([slice_0, slice_1, slice_2])\n",
        "    fig, axes = plt.subplots(1, len(image), figsize=[15,15])\n",
        "    for i, slice in enumerate(image):\n",
        "        axes[i].imshow(slice.T, cmap=\"gray\", origin=\"lower\")\n",
        "        axes[0].set(xlabel=axis2, ylabel=axis3)\n",
        "        axes[1].set(xlabel=axis1, ylabel=axis3)\n",
        "        axes[2].set(xlabel=axis1, ylabel=axis2)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "bd212961-8ff1-44d0-b55c-a6b4749351b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "bd212961-8ff1-44d0-b55c-a6b4749351b0",
        "outputId": "57d02ff5-840e-4328-f120-b51bcbf7095a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x1080 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "show_slices(example[0][0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Create 3D CNN+GRU for classify Schizophrenia vs Control"
      ],
      "metadata": {
        "id": "XhkWP6Pgpla8"
      },
      "id": "XhkWP6Pgpla8"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "fecd6f37-a098-4d1e-8a4b-9a11a6cab833",
      "metadata": {
        "id": "fecd6f37-a098-4d1e-8a4b-9a11a6cab833"
      },
      "outputs": [],
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "\n",
        "class ConvEncoder(nn.Module):\n",
        "    def __init__(self, in_channels=1,\n",
        "                 out_channels_list=[32, 64, 128, 256],\n",
        "                 network_type ='Conv',\n",
        "                 act =\"prelu\",\n",
        "                 norm= \"batch\",\n",
        "                 input_shape=(64, 64, 64),\n",
        "                 is_rcnn=False):\n",
        "        super(ConvEncoder, self).__init__()\n",
        "        self.is_rcnn =is_rcnn\n",
        "        convs =[]\n",
        "        for out_channels in out_channels_list:\n",
        "            if network_type ==\"Residual\":\n",
        "                conv = ResidualUnit(\n",
        "                        spatial_dims=3,\n",
        "                        in_channels=in_channels,\n",
        "                        out_channels=out_channels,\n",
        "                        act=act,\n",
        "                        norm=norm,\n",
        "                        kernel_size=2,\n",
        "                        strides =1,\n",
        "                        padding=1\n",
        "                )\n",
        "                conv.add_module(\"maxpool\", torch.nn.MaxPool3d(kernel_size=2))\n",
        "            else:\n",
        "                conv = Convolution(\n",
        "                        spatial_dims=3,\n",
        "                        in_channels=in_channels,\n",
        "                        out_channels=out_channels,\n",
        "                        act=act,\n",
        "                        norm=norm,\n",
        "                        kernel_size=2,\n",
        "                        strides =1,\n",
        "                        padding=1\n",
        "                )\n",
        "                conv.add_module(\"maxpool\", torch.nn.MaxPool3d(kernel_size=2))\n",
        "            in_channels =out_channels\n",
        "            convs.append(conv)\n",
        "            \n",
        "        self.conv_layer =nn.Sequential(*convs)\n",
        "        input_shape = np.array(input_shape)\n",
        "        self.n_flatten_units = int(np.prod(input_shape // (2 ** len(out_channels_list))) * out_channels)\n",
        "        self.faltten = Flatten()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        if self.is_rcnn:\n",
        "            n_objects, seq_length = x.size()[0:2]\n",
        "            x = x.reshape([n_objects * seq_length] + list(x.size()[2:]))\n",
        "            x = torch.unsqueeze(x, axis=1)\n",
        "            x = self.conv_layer(x)\n",
        "            x =self.faltten(x)\n",
        "            x = x.reshape([n_objects, seq_length, -1])\n",
        "        else:\n",
        "            x = self.conv_layer(x)\n",
        "            x =self.faltten(x)\n",
        "        return x        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "fedcc821-62d8-44d9-b3a3-80a6cd438923",
      "metadata": {
        "id": "fedcc821-62d8-44d9-b3a3-80a6cd438923"
      },
      "outputs": [],
      "source": [
        "class ClfGRU(nn.Module):\n",
        "    def __init__(self, n_latent_units, seq_length, \n",
        "                 hidden_size=128, n_layers=1,\n",
        "                use_states=\"last\"):\n",
        "        super(self.__class__, self).__init__()\n",
        "        self.n_latent_units = n_latent_units\n",
        "        self.seq_length = seq_length\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.gru = nn.GRU(\n",
        "            n_latent_units, \n",
        "            hidden_size, n_layers, \n",
        "            batch_first=True\n",
        "        )\n",
        "        \n",
        "        self.use_states = use_states\n",
        "        if use_states == \"last\":\n",
        "            self.gru_out_size = hidden_size\n",
        "        elif use_states == \"mean\":\n",
        "            self.gru_out_size = hidden_size\n",
        "        elif use_states == \"all\":\n",
        "            self.gru_out_size = hidden_size * seq_length\n",
        "            \n",
        "    def forward(self, x):\n",
        "        out, _ = self.gru(x)\n",
        "        \n",
        "        if self.use_states == \"last\":\n",
        "            out = out[:, -1, :]\n",
        "        elif self.use_states == \"mean\":\n",
        "            out = out.mean(dim=1)\n",
        "        elif self.use_states == \"all\":\n",
        "            out = out.reshape(n_objects, self.hidden_size * seq_length)\n",
        "        \n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "418855bc-3f50-41f8-bd5a-fbc0664ed5ad",
      "metadata": {
        "id": "418855bc-3f50-41f8-bd5a-fbc0664ed5ad"
      },
      "outputs": [],
      "source": [
        "class FMRINET(nn.Module):\n",
        "    def __init__(self, in_channels=10,\n",
        "                 out_channels_list=[32, 64, 128, 256],\n",
        "                 network_type ='Conv',\n",
        "                 act =\"relu\",\n",
        "                 norm= \"batch\",\n",
        "                 input_shape=(64, 64, 64),\n",
        "                 n_outputs =2,\n",
        "                 n_fc_units=128,\n",
        "                 hidden_size=128,\n",
        "                 dropout =0.2,\n",
        "                 n_layers=1,\n",
        "                 is_rcnn=False):\n",
        "        super(FMRINET, self).__init__()\n",
        "        self.is_rcnn=is_rcnn\n",
        "        if self.is_rcnn:\n",
        "            self.cnn =ConvEncoder(in_channels=1,\n",
        "                                    out_channels_list=out_channels_list,\n",
        "                                    network_type =network_type,\n",
        "                                    act =act,\n",
        "                                    norm= norm,\n",
        "                                    input_shape=input_shape,\n",
        "                                    is_rcnn=True)\n",
        "            self.gru =ClfGRU(self.cnn.n_flatten_units, \n",
        "                             in_channels,hidden_size=hidden_size,n_layers=n_layers)\n",
        "            self.fc =nn.Sequential(\n",
        "                               nn.Dropout(dropout),\n",
        "                               nn.Linear(self.gru.gru_out_size, n_fc_units),\n",
        "                               nn.ReLU(inplace=True),\n",
        "                               nn.Linear(n_fc_units, n_outputs))\n",
        "            \n",
        "        else:\n",
        "            self.cnn =ConvEncoder(in_channels=in_channels,\n",
        "                                    out_channels_list=out_channels_list,\n",
        "                                    network_type =network_type,\n",
        "                                    act =act,\n",
        "                                    norm= norm,\n",
        "                                    input_shape=input_shape,\n",
        "                                    is_rcnn=False)\n",
        "            self.fc =nn.Sequential(\n",
        "                              #  nn.Dropout(dropout),\n",
        "                               nn.Linear(self.cnn.n_flatten_units, n_fc_units),\n",
        "                               nn.ReLU(inplace=True),\n",
        "                               nn.Linear(n_fc_units, n_outputs))\n",
        "        \n",
        "    def forward(self,x):\n",
        "        if self.is_rcnn:\n",
        "            x =self.cnn(x)\n",
        "            x =self.gru(x)\n",
        "            x =self.fc(x)\n",
        "        else:\n",
        "            x =self.cnn(x)\n",
        "            x =self.fc(x)\n",
        "        return x    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "f7b58108-58b0-483b-88d2-15aa25db12c7",
      "metadata": {
        "id": "f7b58108-58b0-483b-88d2-15aa25db12c7"
      },
      "outputs": [],
      "source": [
        "model =FMRINET( out_channels_list=[8, 16, 32, 64],\n",
        "                 in_channels=30,\n",
        "                 n_fc_units=64,\n",
        "                 hidden_size=64,\n",
        "                 input_shape=(32, 32, 32),\n",
        "                 dropout =0.1,is_rcnn=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "1a64eacd-41bc-44b9-8cf3-f2d878ddfce2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a64eacd-41bc-44b9-8cf3-f2d878ddfce2",
        "outputId": "6483bdba-e227-4579-cc9f-5c78bd2c901b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "model.cnn.n_flatten_units"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=model.to(device)"
      ],
      "metadata": {
        "id": "Zl5gJTivgs6f"
      },
      "id": "Zl5gJTivgs6f",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "84651cb4-2abf-46f6-acf4-da427c39c786",
      "metadata": {
        "id": "84651cb4-2abf-46f6-acf4-da427c39c786"
      },
      "outputs": [],
      "source": [
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss_and_accuracy(loss_history, train_accuracy, val_accuracy, clear_output=True):\n",
        "    if clear_output:\n",
        "        display.clear_output(wait=True)\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
        "    if loss_history:\n",
        "        ax[0].semilogy(loss_history)\n",
        "        ax[0].set_title('Training loss')\n",
        "        ax[0].set_xlabel('# batches processed')\n",
        "        ax[0].set_ylabel('loss value')\n",
        "    \n",
        "    if len(train_accuracy) > 0:\n",
        "        ax[1].plot(train_accuracy, '*-b', label='train')\n",
        "        ax[1].plot(val_accuracy, '*-r', label='test')\n",
        "        ax[1].set_title('Accuracy')\n",
        "        ax[1].legend()\n",
        "        ax[1].set_xlabel('# epochs processed')\n",
        "        ax[1].set_ylabel('accuracy value')\n",
        "    \n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "YthoFoxcODzk"
      },
      "id": "YthoFoxcODzk",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "torch.backends.cudnn.enabled=False\n",
        "torch.backends.cudnn.deterministic=True"
      ],
      "metadata": {
        "id": "SLDh_2drT-Th"
      },
      "id": "SLDh_2drT-Th",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e6dc4a5-4039-4f15-9e02-e8dcb0fbec60",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e6dc4a5-4039-4f15-9e02-e8dcb0fbec60",
        "outputId": "34c007b4-c533-4569-8a17-b3d0e93e0ae8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "epoch 1/6\n",
            "epoch 1 average loss: 0.6972\n",
            "Current epoch: 1 current train accuracy: 0.4659 \n"
          ]
        }
      ],
      "source": [
        " # start a typical PyTorch training\n",
        "val_interval = 1\n",
        "best_metric = -1\n",
        "best_metric_epoch = -1  \n",
        "train_loss_values, val_loss_values, train_accuracies, val_accuracies = [],[],[],[]\n",
        "writer = SummaryWriter()\n",
        "max_epochs = 6\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    print(\"-\" * 10)\n",
        "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
        "    model.train()\n",
        "    train_loss,val_loss = 0, 0\n",
        "    step = 0\n",
        "\n",
        "    num_correct = 0.0\n",
        "    metric_count = 0\n",
        "    \n",
        "    for batch_data in train_loader:\n",
        "        step += 1\n",
        "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        " \n",
        "        loss = loss_function(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        epoch_len = len(train_ds) // train_loader.batch_size\n",
        "        \n",
        "        value = torch.eq(outputs.argmax(dim=1), labels.argmax(dim=1))\n",
        "        metric_count += len(value)\n",
        "        num_correct += value.sum().item()\n",
        "                \n",
        "        # print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
        "        writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
        "\n",
        "    train_loss /= step\n",
        "    train_loss_values.append(train_loss)\n",
        "    train_metric = num_correct / metric_count\n",
        "    train_accuracies.append(train_metric)\n",
        "    print(f\"epoch {epoch + 1} average loss: {train_loss:.4f}\")\n",
        "    print(f\"Current epoch: {epoch+1} current train accuracy: {train_metric:.4f} \")\n",
        "    writer.add_scalar(\"train_accuracy\", train_metric, epoch + 1)\n",
        "    \n",
        "    if (epoch + 1) % val_interval == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            num_correct = 0.0\n",
        "            metric_count = 0\n",
        "            for val_data in val_loader:\n",
        "                    val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
        "                    val_outputs = model(val_images)\n",
        "                    value = torch.eq(val_outputs.argmax(dim=1), val_labels.argmax(dim=1))\n",
        "                    metric_count += len(value)\n",
        "                    num_correct += value.sum().item()\n",
        "\n",
        "            val_metric = num_correct / metric_count\n",
        "            val_accuracies.append(val_metric)\n",
        "\n",
        "            if val_metric > best_metric:\n",
        "                best_metric = val_metric\n",
        "                best_metric_epoch = epoch + 1\n",
        "                torch.save(model.state_dict(), \"best_metric_model_classification3d_array.pth\")\n",
        "                print(\"saved new best metric model\")\n",
        "\n",
        "            print(f\"Current epoch: {epoch+1} current accuracy: {val_metric:.4f} \")\n",
        "            print(f\"Best accuracy: {best_metric:.4f} at epoch {best_metric_epoch}\")\n",
        "            writer.add_scalar(\"val_accuracy\", val_metric, epoch + 1)\n",
        "        plot_loss_and_accuracy(train_loss_values,train_accuracies, val_accuracies, clear_output=True)\n",
        "print(f\"Training completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "osS8Aplmvynz"
      },
      "id": "osS8Aplmvynz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TO DO: Try to improve the quality of the classifacation ( Schizophrenia VS Control)\n",
        "  1. Try ResidualUnit Blocks, LSTM block , different numbers of blocks\n",
        "  2. Add schedulers + hyperparameter optimization (lr, weight decay)\n",
        "  3. Add augmentations from MONAI\n",
        "  4. Write report with comparison of all methods +code \n",
        "\n",
        "Second part:\n",
        "  1. Extract ROI from fMRI, build connectivity  matrices\n",
        "  2. Train 2D CNN model from MONAI on connectivity  matrices\n",
        "  3. Write report with comparison of all methods +code "
      ],
      "metadata": {
        "id": "KIPnA2LyqDRD"
      },
      "id": "KIPnA2LyqDRD"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}